{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bcc92f1-4746-4814-90f8-dad6f1fabb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash_bootstrap_components in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: dash>=2.0.0 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash_bootstrap_components) (2.16.1)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (3.0.2)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (3.0.1)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (5.20.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (6.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (4.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (2.31.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (1.5.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from dash>=2.0.0->dash_bootstrap_components) (58.1.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata->dash>=2.0.0->dash_bootstrap_components) (3.17.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (8.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (21.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from Werkzeug<3.1->dash>=2.0.0->dash_bootstrap_components) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from retrying->dash>=2.0.0->dash_bootstrap_components) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click>=8.1.3->Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aiko\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (3.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install dash_bootstrap_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c3163e-e045-44ee-a4c4-dedd2241f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import random\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f77750-116a-452e-a3c4-a625a5a4fe7b",
   "metadata": {},
   "source": [
    "Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772628f0-5b87-4e48-bfb8-49e6ff3a6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_default_graph():\n",
    "    # Merge the dataframes\n",
    "    all_data = data.merge(topic_df, on='review', how='inner')\n",
    "\n",
    "    # Clean the date\n",
    "    all_data['date_clean'] = pd.to_datetime(all_data['date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    all_data['date_clean'] = all_data['date_clean'].combine_first(pd.to_datetime(all_data['date'], format='%Y-%m-%dT%H:%M:%S.%fZ', errors='coerce'))\n",
    "    all_data['date_clean'] = all_data['date_clean'].astype(str).str[:10]\n",
    "    all_data['date_clean'] = pd.to_datetime(all_data['date_clean']).dt.date\n",
    "\n",
    "    # Select columns needed\n",
    "    df = all_data[['review', 'date_clean', 'Topic_Name', 'Topic_Number']]\n",
    "    get_topic_name = {\n",
    "        0: 'App Responsiveness', 1: 'Money Growth (Interest Rates)', 2: 'Customer Services',\n",
    "        3: 'Services & Products', 4: 'User Interface', 5: 'Credit card',\n",
    "        6: 'Login & Account Setup', 7: 'Competition', 8: 'Safety', 9: 'Customer trust'\n",
    "    }\n",
    "\n",
    "    # Split reviews with multiple topics into duplicates of single topics\n",
    "    df['Topic_Number'] = df['Topic_Number'].astype(str)\n",
    "    df2 = df[df['Topic_Number'].str.contains(',', regex=False)].copy()\n",
    "\n",
    "    # Hard coding cos splitting by regex is killing me\n",
    "    df['Topic_Number'] = df['Topic_Number'].str[0]\n",
    "    df['Topic_Number'] = df['Topic_Number'].astype(int)\n",
    "    df['Topic_Name'] = df['Topic_Number'].map(get_topic_name)\n",
    "\n",
    "    df2['Topic_Number'] = df2['Topic_Number'].str[2]\n",
    "    df2['Topic_Number'] = df2['Topic_Number'].astype(int)\n",
    "    df2['Topic_Name'] = df2['Topic_Number'].map(get_topic_name)\n",
    "\n",
    "    df = pd.concat([df, df2])\n",
    "\n",
    "    # Group by topic, number, and date\n",
    "    df = df.groupby(['Topic_Name', 'Topic_Number', 'date_clean']).size().reset_index(name='num_reviews')\n",
    "\n",
    "    # Select date range\n",
    "    s = df.date_clean.iloc[5]\n",
    "    e = df.date_clean.iloc[10]\n",
    "\n",
    "    # Create the default graph\n",
    "    topics_over_time = px.line(df, 'date_clean', 'num_reviews', color='Topic_Name',\n",
    "                               labels={\"date_clean\": \"Date\", \"num_reviews\": \"Number of Reviews\", \"Topic_Name\": \"Topic\"},\n",
    "                               title=\"Number of Reviews by Topics over time\")\n",
    "    # Update date range\n",
    "    topics_over_time.update_xaxes(range=[s, e])\n",
    "\n",
    "    return topics_over_time\n",
    "\n",
    "def get_date_range():\n",
    "    # Merge the dataframes\n",
    "    all_data = data.merge(topic_df, on='review', how='inner')\n",
    "\n",
    "    # Clean the date\n",
    "    all_data['date_clean'] = pd.to_datetime(all_data['date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    all_data['date_clean'] = all_data['date_clean'].combine_first(pd.to_datetime(all_data['date'], format='%Y-%m-%dT%H:%M:%S.%fZ', errors='coerce'))\n",
    "    all_data['date_clean'] = all_data['date_clean'].astype(str).str[:10]\n",
    "\n",
    "    min_date = all_data.date_clean.min()\n",
    "    max_date = all_data.date_clean.max()\n",
    "    return [min_date, max_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c887b2-dc63-453e-9e60-57d08a1078cc",
   "metadata": {},
   "source": [
    "Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68bd82d-0fb1-4bbd-ba74-a6899a74b43f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'App Responsiveness.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23860\\2677748430.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapp_responsiveness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'App Responsiveness.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcompetition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Competition.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcredit_card\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Credit card.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcustomer_service\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Customer Services.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcustomer_trust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Customer trust.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'App Responsiveness.csv'"
     ]
    }
   ],
   "source": [
    "app_responsiveness = pd.read_csv('App Responsiveness.csv')\n",
    "competition = pd.read_csv('Competition.csv')\n",
    "credit_card = pd.read_csv('Credit card.csv')\n",
    "customer_service = pd.read_csv('Customer Services.csv')\n",
    "customer_trust = pd.read_csv('Customer trust.csv')\n",
    "login_account = pd.read_csv('Login & Account Setup.csv')\n",
    "money_growth = pd.read_csv('Money Growth (Interest Rates).csv')\n",
    "safety = pd.read_csv('Safety.csv')\n",
    "service_products = pd.read_csv('Services & Products.csv')\n",
    "user_interface = pd.read_csv('User Interface.csv')\n",
    "data = pd.read_csv('combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17609b7-eb3d-4dd8-9b5f-87bd1c3e27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "topics = ['', 'App Responsiveness', 'Competition', 'Credit Card Usage', 'Customer Services', 'Customer Trust',\n",
    "          'Login & Account Setup', 'Money Growth (Interest Rates)', 'Safety', 'Service Products', 'User Interface']\n",
    "\n",
    "datasets = {\n",
    "    'App Responsiveness': app_responsiveness,\n",
    "    'Competition': competition,\n",
    "    'Credit Card Usage': credit_card,\n",
    "    'Customer Services': customer_service,\n",
    "    'Customer Trust': customer_trust,\n",
    "    'Login & Account Setup': login_account,\n",
    "    'Money Growth (Interest Rates)': money_growth,\n",
    "    'Safety': safety,\n",
    "    'Service Products': service_products,\n",
    "    'User Interface': user_interface\n",
    "}\n",
    "\n",
    "# Issue method\n",
    "def issue(data, df):\n",
    "    # Merge the two DataFrames on the 'review' column\n",
    "    merged = pd.merge(data, df, on='review', how='inner')\n",
    "    # Drop the 'Unnamed: 0' column\n",
    "    merged.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    # Rename the 'key' column to 'issue'\n",
    "    merged.rename(columns={'key': 'issue'}, inplace=True)\n",
    "    # Convert 'date' column to datetime format\n",
    "    merged['date'] = pd.to_datetime(merged['date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    # If the previous conversion fails, try a different format\n",
    "    merged['date'] = merged['date'].combine_first(pd.to_datetime(merged['date'], format='%Y-%m-%dT%H:%M:%S.%fZ', errors='coerce'))\n",
    "    # Convert 'date' column to string\n",
    "    merged['date'] = merged['date'].astype(str)\n",
    "    # Extract date only (YYYY-MM-DD)\n",
    "    merged['date_only'] = merged['date'].str[:10]\n",
    "    grouped_data = merged.groupby(['date_only', 'issue']).size().reset_index(name='count')\n",
    "    # Convert 'date_only' to datetime if it's not already in datetime format\n",
    "    grouped_data['date_only'] = pd.to_datetime(grouped_data['date_only'])\n",
    "    # Aggregate data by month and issue\n",
    "    grouped_data['month_year'] = grouped_data['date_only'].dt.to_period('M')\n",
    "    monthly_data = grouped_data.groupby(['month_year', 'issue']).size().reset_index(name='count')\n",
    "    # Calculate total count for each issue\n",
    "    issue_totals = monthly_data.groupby('issue')['count'].sum().sort_values(ascending=False)\n",
    "    # Select top n issues\n",
    "    top_issues = issue_totals.head(5).index\n",
    "    return top_issues \n",
    "\n",
    "# Initialize an empty dictionary to store the top issues for each topic\n",
    "issues = {}\n",
    "\n",
    "# Call preprocess for each key in the datasets dictionary\n",
    "for topic, df in datasets.items():\n",
    "    top_issues = issue(data, df)\n",
    "    issues[topic] = top_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d37ce30-c839-4629-9625-99abea1d6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, df):\n",
    "    # Merge the two DataFrames on the 'review' column\n",
    "    merged = pd.merge(data, df, on='review', how='inner')\n",
    "\n",
    "    # Drop the 'Unnamed: 0' column\n",
    "    merged.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    # Rename the 'key' column to 'issue'\n",
    "    merged.rename(columns={'key': 'issue'}, inplace=True)\n",
    "\n",
    "    # Convert 'date' column to datetime format\n",
    "    merged['date'] = pd.to_datetime(merged['date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "    # If the previous conversion fails, try a different format\n",
    "    merged['date'] = merged['date'].combine_first(pd.to_datetime(merged['date'], format='%Y-%m-%dT%H:%M:%S.%fZ', errors='coerce'))\n",
    "\n",
    "    # Convert 'date' column to string\n",
    "    merged['date'] = merged['date'].astype(str)\n",
    "\n",
    "    # Extract date only (YYYY-MM-DD)\n",
    "    merged['date_only'] = merged['date'].str[:10]\n",
    "\n",
    "    return merged\n",
    "\n",
    "def plot_top_n_issues_time_series(merged_data):\n",
    "    # Create a time series line plot\n",
    "    grouped_data = merged_data.groupby(['date_only', 'issue']).size().reset_index(name='count')\n",
    "\n",
    "    # Convert 'date_only' to datetime if it's not already in datetime format\n",
    "    grouped_data['date_only'] = pd.to_datetime(grouped_data['date_only'])\n",
    "\n",
    "    # Aggregate data by month and issue\n",
    "    grouped_data['month_year'] = grouped_data['date_only'].dt.to_period('M')\n",
    "    monthly_data = grouped_data.groupby(['month_year', 'issue']).size().reset_index(name='count')\n",
    "\n",
    "    # Calculate total count for each issue\n",
    "    issue_totals = monthly_data.groupby('issue')['count'].sum().sort_values(ascending=False)\n",
    "\n",
    "    # Select top n issues\n",
    "    top_issues = issue_totals.head(5).index\n",
    "\n",
    "    # Filter monthly_data for top n issues\n",
    "    monthly_data_top = monthly_data[monthly_data['issue'].isin(top_issues)]\n",
    "\n",
    "    # Convert 'month_year' to string format\n",
    "    monthly_data_top.loc[:, 'month_year'] = monthly_data_top['month_year'].astype(str)\n",
    "\n",
    "    # Create a time series line plot\n",
    "    fig = px.line(monthly_data_top, x='month_year', y='count', color='issue', title=f'Number of Reviews by Top 5 Issues Over Time')\n",
    "    \n",
    "    # Add markers to the lines\n",
    "    for trace in fig.data:\n",
    "        trace.update(mode='lines+markers')\n",
    "    fig.update_xaxes(title_text='Month')\n",
    "    fig.update_yaxes(title_text='Number of Reviews')\n",
    "    fig.update_yaxes(fixedrange=True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77491515-fcc4-4843-8469-14808beffb31",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'combined_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23860\\1487622956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdash\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexternal_stylesheets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthemes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBOOTSTRAP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'combined_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtopic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'topics_review.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Natalie\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'combined_data.csv'"
     ]
    }
   ],
   "source": [
    "# Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "data = pd.read_csv('combined_data.csv')\n",
    "topic_df = pd.read_csv('topics_review.csv')\n",
    "\n",
    "# Issues page layout\n",
    "issues_layout = html.Div(\n",
    "    [\n",
    "        html.H1(\"Issues Faced\"),\n",
    "        html.H3(\"Select an issue to view details\"),\n",
    "        html.Br(),\n",
    "        dcc.DatePickerRange(\n",
    "            id='date_picker_range',\n",
    "            min_date_allowed=get_date_range()[0],\n",
    "            max_date_allowed=get_date_range()[1],\n",
    "            initial_visible_month=get_date_range()[0],\n",
    "            end_date=get_date_range()[1]),\n",
    "        html.Br(),\n",
    "        dcc.Dropdown(\n",
    "            id=\"topic-dropdown\",\n",
    "            options=[{\"label\": topic, \"value\": topic} for topic in topics],\n",
    "            value=topics[0],\n",
    "        ),\n",
    "        dcc.Graph(id=\"issues-line-chart\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# App layout\n",
    "app.layout = issues_layout\n",
    "\n",
    "def update_date_range(fig, start_date, end_date):\n",
    "    if start_date is None:\n",
    "        start_date = get_date_range()[0]\n",
    "    if end_date is None:\n",
    "        end_date = get_date_range()[1]\n",
    "    fig.update_xaxes(range=[start_date,end_date])\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"issues-line-chart\", \"figure\"),\n",
    "    [Input(\"topic-dropdown\", \"value\"),\n",
    "    Input('date_picker_range', 'start_date'),\n",
    "    Input('date_picker_range', 'end_date')]\n",
    ")\n",
    "def update_issues_page(topic,start_date,end_date):\n",
    "    if not topic:  # Check if topic is None or empty string\n",
    "        # Return default graph\n",
    "        default_fig = plot_default_graph()\n",
    "        update_date_range(default_fig,start_date,end_date)\n",
    "        return default_fig\n",
    "    else:\n",
    "        print(f\"Selected topic: {topic}\")\n",
    "        # Define a dictionary mapping topics to their respective DataFrames\n",
    "        topic_to_df = {\n",
    "            'App Responsiveness': app_responsiveness,\n",
    "            'Competition': competition,\n",
    "            'Credit Card Usage': credit_card,\n",
    "            'Customer Services': customer_service,\n",
    "            'Customer Trust': customer_trust,\n",
    "            'Login & Account Setup': login_account,\n",
    "            'Money Growth (Interest Rates)': money_growth,\n",
    "            'Safety': safety,\n",
    "            'Service Products': service_products,\n",
    "            'User Interface': user_interface\n",
    "        }\n",
    "\n",
    "        # Get the DataFrame for the selected topic\n",
    "        df = topic_to_df[topic]\n",
    "        cleaned_df = preprocess(data, df)\n",
    "        # Call plot_top_n_issues_time_series function to generate the figure\n",
    "        fig = plot_top_n_issues_time_series(cleaned_df)\n",
    "        update_date_range(fig,start_date,end_date)\n",
    "        return fig\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7e4f2-a16c-4b03-990b-bb8e6cb2883a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
