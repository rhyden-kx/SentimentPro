{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path):\n",
    "    review_data = pd.read_csv(path)\n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(review_data):\n",
    "    review_data['clean_review'] = review_data['review'].str.lower()\n",
    "    review_data['clean_review'] = review_data['clean_review'].str.replace(r'[^a-zA-Z\\s]', ' ',regex=True) \n",
    "    review_data['clean_review'] = review_data['clean_review'].str.replace(r'\\s{2,}', ' ',regex=True)\n",
    "    review_data['clean_review'] = review_data['clean_review'].apply(word_tokenize)\n",
    "    review_data['clean_review'] = review_data['clean_review'].apply(lambda x:[word for word in x if word not in stopwords.words(\"english\") and len(word) > 3 and word.isalpha()])\n",
    "    review_data['clean_review'] = review_data['clean_review'].apply(lambda x: [WordNetLemmatizer().lemmatize(word) for word in x])\n",
    "    review_data['clean_review'] = review_data['clean_review'].apply(lambda x: [word for word in x if nltk.pos_tag([word])[0][1] == 'NN'])\n",
    "    review_data = review_data[review_data['clean_review'].map(lambda x: len(x)) > 1].reset_index(drop=True)\n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_creation(review_data):\n",
    "    texts = review_data['clean_review']\n",
    "    id2word = corpora.Dictionary(texts)\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    return texts, id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mallet(system,folder_path):\n",
    "    os.environ['MALLET_HOME']=folder_path\n",
    "    if system == 'windows': mallet_path = folder_path+\"\\\\bin\\\\mallet.bat\"\n",
    "    elif system == 'mac': mallet_path = folder_path+\"/bin/mallet\"\n",
    "    return mallet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mallet(mallet_path,num_topics,id2word,corpus):\n",
    "    ldamallet = LdaMallet(mallet_path=mallet_path,num_topics=num_topics,corpus=corpus,id2word=id2word,random_seed=10)\n",
    "    return ldamallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_match(model,corpus,texts,data):\n",
    "    output = pd.DataFrame()\n",
    "    topics = {'0':'App Responsiveness',\n",
    "              '1':'Money Growth (Interest Rates)',\n",
    "              '2':'Customer Services',\n",
    "              '3':'Services & Products',\n",
    "              '4':'User Interface',\n",
    "              '5':'Credit card',\n",
    "              '6':'Login & Account Setup',\n",
    "              '7':'Competition',\n",
    "              '8':'Safety',\n",
    "              '9':'Customer trust'}\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(model[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        print(i,row)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        if not texts[i]:\n",
    "            output = output.append(pd.Series([10,'Others',1.000,'']),ignore_index=True)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = model.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                output = output.append(pd.Series([int(topic_num),topics[str(int(topic_num))], round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    output.columns = ['Topic Number', 'Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "    output = pd.concat([data,output], axis=1)\n",
    "    output = output.drop(['clean_review','Perc_Contribution','Topic_Keywords'],axis=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = load(\"https://github.com/rhyden-kx/SentimentPro/blob/main/data/Reviews.csv?raw=true\")\n",
    "review_data = processing(review_data=review_data)\n",
    "texts, id2word, corpus = matrix_creation(review_data=review_data)\n",
    "mallet_path = load_mallet(\"windows\",\"C:\\\\Users\\\\user\\\\Downloads\\\\mallet-2.0.8\\\\mallet-2.0.8\")\n",
    "mallet = create_mallet(mallet_path=mallet_path,num_topics=10,id2word=id2word,corpus=corpus)\n",
    "output = topic_match(model=mallet,corpus=corpus,texts=texts,data=review_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
